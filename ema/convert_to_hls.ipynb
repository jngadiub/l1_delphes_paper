{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import setGPU\n",
    "import hls4ml\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, BatchNormalization, Activation, Concatenate, Dropout, Layer\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU, Reshape\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from qkeras import QDense, QActivation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from custom_layers import KLLoss, Sampling, Radius, CustomMSE\n",
    "from functions import load_model\n",
    "\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation', 'KLLoss']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND_CONV'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# Data = (N,19,3,1).flatten()\n",

    "with open('/eos/user/e/epuljak/forDelphes/Delphes_QCD_BSM_data.pkl', 'rb') as f:\n",
    "    X_train_flatten, X_train_scaled, X_test_flatten, X_test_scaled, bsm_data, bsm_target, pt_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/eos/user/e/epuljak/autoencoder_models/test_data.pkl', 'rb') as f:\n",
    "#     data = [X_test_flatten, bsm_data, pt_scaler]\n",
    "#     pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    X_test_flatten, bsm_data, pt_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define do you want to create KL layer (False if it's standard autoencoder)\n",
    "KL_layer = False\n",
    "# define do you want to create MSE layer (False if it's variational autoencoder)\n",
    "MSE_layer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chosen model\n",
    "custom_objects={'QDense': QDense, 'QActivation': QActivation, 'Sampling': Sampling}\n",
    "\n",
    "#final_encoder = load_model('VAE_models/final_models/VAE_encoder_qkeras8_qinput', custom_objects=custom_objects)\n",
    "#final_decoder = load_model('VAE_models/final_models/VAE_decoder_qkeras8_qinput', custom_objects=custom_objects)\n",
    "\n",
    "autoencoder = load_model('/eos/user/e/epuljak/autoencoder_models/AE_qkeras8_notprunedw', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check quantizers\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, \"kernel_quantizer\"):\n",
    "        print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal))\n",
    "    elif hasattr(layer, \"quantizer\"):\n",
    "        print(layer.name, \"quantizer:\", str(layer.quantizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it's encoder\n",
    "#pred_mean, pred_logvar, _ = model.predict(X_test_flatten[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if kl loss has correct values\n",
    "# from losses import kl_loss\n",
    "# print(pred_mean)\n",
    "# print(pred_logvar)\n",
    "# print('KL LOSS: ', kl_loss(pred_mean, pred_logvar))\n",
    "# print('sigma: ', np.sqrt(np.exp(pred_logvar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mu and sigma from model\n",
    "if KL_layer:\n",
    "    z_mean = final_encoder.layers[-3].output\n",
    "    z_log_var = final_encoder.layers[-2].output\n",
    "    # calculate KL distance with the custom layer\n",
    "    custom_output = KLLoss()([z_mean, z_log_var])\n",
    "    # create new model\n",
    "    custom_model = Model(inputs=final_encoder.input, outputs=custom_output)\n",
    "    custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MSE_layer:\n",
    "    true = model.input\n",
    "    predicted = model.layers[-1].output\n",
    "    reshaped_predicted = Reshape((19,3,1), name='reshaped_predicted')(predicted)\n",
    "\n",
    "    scaled_input = BatchNormalization(trainable=False, name='scaled_input')(true)\n",
    "    reshaped_scaled_input = Reshape((19,3,1), name='reshaped_scaled_input')(scaled_input)\n",
    "    # calculate MSE between them\n",
    "    custom_output = CustomMSE()([reshaped_scaled_input, reshaped_predicted])\n",
    "    # create new model\n",
    "    custom_model = Model(inputs=model.input, outputs=custom_output)\n",
    "    \"\"\" Keras BatchNorm layer returns\n",
    "        gamma * (batch - self.moving_mean) / sqrt(self.moving_var + epsilon) + beta\n",
    "        epsilon=0.001\n",
    "        momentum=0.99\n",
    "        moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)\n",
    "        moving_variance = moving_var * momentum + var(batch) * (1 - momentum)\n",
    "        pt_scaler\n",
    "        pt_scaler.mean_\n",
    "        pt_scaler.var_\n",
    "    \"\"\"\n",
    "    # with open('output/data_-1.pickle', 'rb') as f:\n",
    "    #     x_train, y_train, _, _, _, pt_scaler = pickle.load(f)\n",
    "    mean_ = np.zeros((57,))\n",
    "    var_ = np.ones((57,))\n",
    "    for i in range(19):\n",
    "        mean_[3*i] = pt_scaler.mean_[i]\n",
    "        var_[3*i] = pt_scaler.var_[i]\n",
    "    # order of weights is (gamma,beta,mean,std)\n",
    "    custom_model.get_layer('scaled_input').set_weights((np.ones((57,)),np.zeros((57,)),mean_,var_))\n",
    "    custom_model.summary()\n",
    "    custom_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-processing",
   "metadata": {},
   "source": [
    "## Convert to HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config(config):\n",
    "    #config['Model']['Strategy'] = 'Resource'\n",
    "    config['LayerName']['input_1'].update({\n",
    "        'Precision': 'ap_fixed<16,10>'\n",
    "        })\n",
    "    \n",
    "#     config['LayerName']['kl_loss'].update({\n",
    "#                 'Precision': {\n",
    "#                     'accum': 'ap_fixed<32,16,AP_RND,AP_SAT>',\n",
    "#                     'result': 'ap_fixed<32,16>'\n",
    "#                 },\n",
    "#                 'sum_t': 'ap_fixed<32,16>',\n",
    "#                 'exp_table_t': 'ap_fixed<32,16,AP_RND,AP_SAT>',\n",
    "#                 'table_size': 1024*4\n",
    "#             })\n",
    "    config['LayerName']['custom_mse']['Precision'].update({\n",
    "            'result': 'ap_fixed<16, 10, AP_RND_CONV, AP_SAT>'\n",
    "        })\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardware = 'xcvu9p-flgb2104-2-e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(custom_model, \n",
    "                                              default_precision='ap_fixed<16,6,AP_RND_CONV,AP_SAT>',\n",
    "                                                max_bits=20,\n",
    "                                                data_type_mode='auto_accum', # auto_accum_only\n",
    "                                                granularity='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = update_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hls4ml.utils.config import set_accum_from_keras_model\n",
    "set_accum_from_keras_model(config, custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(custom_model,\n",
    "                                                           hls_config=config,\n",
    "                                                           output_dir='output/dense_AE/xcvu9p/',\n",
    "                                                           fpga_part=hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/eos/user/e/epuljak/autoencoder_models/config_AE_HLS.pickle', 'wb') as handle:\n",
    "    pickle.dump(config, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tu zapne!\n",
    "hls4ml.model.profiling.numerical(model=custom_model, hls_model=hls_model, X=X_test_flatten[:10000])\n",
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file='AE_HLS.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.model.profiling.compare(keras_model, hls_model, X_test_flatten[:1000000], 'dist_diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-pride",
   "metadata": {},
   "source": [
    "## Trace and inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in config['LayerName'].keys():\n",
    "    config['LayerName'][layer]['Trace'] = True\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(custom_model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='output/dense/xcvu9p/',\n",
    "                                                       fpga_part=hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take hls model predictions\n",
    "hls_model.compile()\n",
    "y_hls = hls_model.predict(X_test_flatten[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take keras model predictions\n",
    "keras_model = custom_model\n",
    "keras_model.compile()\n",
    "# predictions keras model\n",
    "y = keras_model.predict(X_test_flatten[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace\n",
    "hls4ml_pred, hls4ml_trace = hls_model.trace(X_test_flatten[:10000])\n",
    "\n",
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(custom_model, X_test_flatten[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracing\n",
    "kl_loss_total = []\n",
    "for layer in keras_trace.keys():\n",
    "    if layer in hls4ml_trace.keys():\n",
    "        print(f'Keras layer {layer}, first sample:')\n",
    "        print(config['LayerName'][layer])\n",
    "        print(keras_trace[layer][1].flatten()-hls4ml_trace[layer][1].flatten())\n",
    "        print(\"========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_keys = list()\n",
    "# for k in list(keras_trace.keys()):\n",
    "#     for h in list(hls4ml_trace.keys()):\n",
    "#         if k == h and k not in new_keys and not k.startswith('batch') : new_keys.append(k)\n",
    "#     if k.startswith('batch'): new_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output layer by layer\n",
    "for layer in new_keys:\n",
    "    print(\"================================================\")\n",
    "    if layer.startswith('batch_normalization_'):\n",
    "        print(\"Keras layer %s, first sample:\"%layer)\n",
    "        print(keras_trace[layer][0])\n",
    "        \n",
    "        print(\"hls4ml layer %s, first sample:\"%layer)\n",
    "        print(hls4ml_trace[layer][0])\n",
    "    else:\n",
    "        print(\"Keras layer %s, first sample:\"%layer)\n",
    "        print(keras_trace[layer][0])\n",
    "        print(\"hls4ml layer %s, first sample:\"%layer)\n",
    "        print(hls4ml_trace[layer][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True,\n",
    "        to_file=f'plots/hls-model.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-elizabeth",
   "metadata": {},
   "source": [
    "### Check ROCs for Keras vs HLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hls = hls_model.predict(X_test_flatten[:2000000])\n",
    "y_keras = keras_model.predict(X_test_flatten[:2000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the results are the same without KL layer as output\n",
    "\n",
    "# for layer in keras_trace.keys():\n",
    "#     if layer in hls4ml_trace.keys():\n",
    "#         if layer == 'q_dense_2': \n",
    "#             mean_qcd_keras = keras_trace[layer]\n",
    "#             mean_qcd_hls = hls4ml_trace[layer]\n",
    "#         if layer == 'q_dense_3': \n",
    "#             logvar_qcd_keras = keras_trace[layer]\n",
    "#             logvar_qcd_hls = hls4ml_trace[layer]\n",
    "#         print(\"========================================================================\")\n",
    "\n",
    "# from losses import kl_loss\n",
    "\n",
    "# kl_loss_total = []\n",
    "# kl_loss_total.append(kl_loss(mean_qcd_keras, logvar_qcd_keras))\n",
    "# kl_loss_total.append(kl_loss(mean_qcd_hls, logvar_qcd_hls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_total = []\n",
    "loss_total.append(y)\n",
    "loss_total.append(y_hls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm_labels = ['Leptoquark','A to 4 leptons', 'hChToTauNu', 'hToTauTau']\n",
    "labels = ['QCD keras', 'QCD hls',\\\n",
    "          r'keras LQ $\\rightarrow$ b$\\tau$', r'hls LQ $\\rightarrow$ b$\\tau$',\\\n",
    "          r'keras A $\\rightarrow$ 4L', r'hls A $\\rightarrow$ 4L',\\\n",
    "          r'keras $h_{\\pm} \\rightarrow \\tau\\nu$', r'hls $h_{\\pm} \\rightarrow \\tau\\nu$',\\\n",
    "          r'keras $h_{0} \\rightarrow \\tau\\tau$', r'hls $h_{0} \\rightarrow \\tau\\tau$']\n",
    "loss = '$D_{KL}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the results are the same without KL layer as output\n",
    "# bsm_results = []\n",
    "\n",
    "# for i, label in enumerate(bsm_labels):\n",
    "#     hls4ml_pred, hls4ml_trace = hls_model.trace(bsm_data[i])\n",
    "#     keras_trace = hls4ml.model.profiling.get_ymodel_keras(custom_model, bsm_data[i])\n",
    "#     for layer in keras_trace.keys():\n",
    "#         if layer in hls4ml_trace.keys():\n",
    "#             if layer == 'q_dense_2': \n",
    "#                 mean_bsm_keras = keras_trace[layer]\n",
    "#                 mean_bsm_hls = hls4ml_trace[layer]\n",
    "#             if layer == 'q_dense_3': \n",
    "#                 logvar_bsm_keras = keras_trace[layer]\n",
    "#                 logvar_bsm_hls = hls4ml_trace[layer]\n",
    "#     kl_loss_total.append(kl_loss(mean_bsm_keras, logvar_bsm_keras))\n",
    "#     kl_loss_total.append(kl_loss(mean_bsm_hls, logvar_bsm_hls))\n",
    "#     print(\"========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(bsm_labels):\n",
    "    hls4ml_pred = hls_model.predict(bsm_data[i])\n",
    "    keras_pred = keras_model.predict(bsm_data[i])\n",
    "    \n",
    "    loss_total.append(keras_pred)\n",
    "    loss_total.append(hls4ml_pred)\n",
    "    print(\"========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_result = 'AE_result_HLS.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5f = h5py.File(output_result, 'w')\n",
    "# h5f.create_dataset('QCD', data = X_test_scaled)\n",
    "# h5f.create_dataset('QCD_input', data=X_test_flatten)\n",
    "# h5f.create_dataset('predicted_QCD', data = qcd_pred)\n",
    "# for i, bsm in enumerate(bsm_results):\n",
    "#     h5f.create_dataset('%s_scaled' %bsm[0], data=bsm[1])\n",
    "#     h5f.create_dataset('%s_input' %bsm[0], data=bsm_data[i])\n",
    "#     h5f.create_dataset('predicted_%s' %bsm[0], data=bsm[2])\n",
    "\n",
    "# h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "minScore = 999999.\n",
    "maxScore = 0\n",
    "for i in range(len(labels)):\n",
    "    thisMin = np.min(loss_total[i])\n",
    "    thisMax = np.max(loss_total[i])\n",
    "    minScore = min(thisMin, minScore)\n",
    "    maxScore = max(maxScore, thisMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['C1','C2', 'C3', 'C4', 'C5', 'C6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size=100\n",
    "plt.figure(figsize=(10,8))\n",
    "z = 0\n",
    "for i, label in enumerate(labels):\n",
    "    if i%2==0:\n",
    "        plt.hist(loss_total[i].reshape(loss_total[i].shape[0]*1), bins=bin_size, label=label, density = True, range=(minScore, maxScore),\n",
    "         histtype='step', fill=False, linewidth=1.5, color=colors[z])\n",
    "    if i%2==1:\n",
    "        plt.hist(loss_total[i].reshape(loss_total[i].shape[0]*1), bins=bin_size, label=label, density = True, range=(minScore, maxScore),\n",
    "         histtype='step', fill=False, linewidth=1.5, alpha=0.6, color=colors[z])\n",
    "        z = z+1\n",
    "#plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.title('KL loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "tpr_lq=[];fpr_lq=[];auc_lq=[]\n",
    "tpr_ato4l=[];fpr_ato4l=[];auc_ato4l=[]\n",
    "tpr_ch=[];fpr_ch=[];auc_ch=[]\n",
    "tpr_to=[];fpr_to=[];auc_to=[]\n",
    "\n",
    "\n",
    "target_qcd = np.zeros(loss_total[0].shape[0])\n",
    "target_qcd_hls = np.zeros(loss_total[1].shape[0])\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    if i == 0 and i==1: continue\n",
    "    if i%2==0:\n",
    "        trueVal = np.concatenate((np.ones(loss_total[i].shape[0]), target_qcd))\n",
    "        predVal_loss = np.concatenate((loss_total[i], loss_total[0]))\n",
    "\n",
    "        fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "\n",
    "        auc_loss = auc(fpr_loss, tpr_loss)\n",
    "        if i==2:\n",
    "            tpr_lq.append(tpr_loss)\n",
    "            fpr_lq.append(fpr_loss)\n",
    "            auc_lq.append(auc_loss)\n",
    "        elif i == 4:\n",
    "            tpr_ato4l.append(tpr_loss)\n",
    "            fpr_ato4l.append(fpr_loss)\n",
    "            auc_ato4l.append(auc_loss)\n",
    "        elif i==6:\n",
    "            tpr_ch.append(tpr_loss)\n",
    "            fpr_ch.append(fpr_loss)\n",
    "            auc_ch.append(auc_loss)\n",
    "        elif i == 8:\n",
    "            tpr_to.append(tpr_loss)\n",
    "            fpr_to.append(fpr_loss)\n",
    "            auc_to.append(auc_loss)\n",
    "    if i%2==1:\n",
    "        trueVal = np.concatenate((np.ones(loss_total[i].shape[0]), target_qcd_hls))\n",
    "        predVal_loss = np.concatenate((loss_total[i], loss_total[1]))\n",
    "\n",
    "        fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "\n",
    "        auc_loss = auc(fpr_loss, tpr_loss)\n",
    "        if i==3:\n",
    "            tpr_lq.append(tpr_loss)\n",
    "            fpr_lq.append(fpr_loss)\n",
    "            auc_lq.append(auc_loss)\n",
    "        elif i == 5:\n",
    "            tpr_ato4l.append(tpr_loss)\n",
    "            fpr_ato4l.append(fpr_loss)\n",
    "            auc_ato4l.append(auc_loss)\n",
    "        elif i==7:\n",
    "            tpr_ch.append(tpr_loss)\n",
    "            fpr_ch.append(fpr_loss)\n",
    "            auc_ch.append(auc_loss)\n",
    "        elif i == 9:\n",
    "            tpr_to.append(tpr_loss)\n",
    "            fpr_to.append(fpr_loss)\n",
    "            auc_to.append(auc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for i, (tpr, fpr, auc, L) in enumerate(zip(tpr_lq[:], fpr_lq[:], auc_lq[:], labels[2:4])):\n",
    "    if i == 1:\n",
    "        plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L,auc*100.), linewidth=1.5, color=colors[0], alpha=0.6)\n",
    "    else: plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L,auc*100.), linewidth=1.5, color=colors[0])\n",
    "\n",
    "for i, (tpr, fpr, auc, L) in enumerate(zip(tpr_ato4l[:], fpr_ato4l[:], auc_ato4l[:], labels[4:6])):\n",
    "    if i == 1: plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L,auc*100.), linewidth=1.5, color=colors[1], alpha = 0.6)\n",
    "    else: plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L,auc*100.), linewidth=1.5, color=colors[1])\n",
    "for i, (tpr, fpr, auc, L) in enumerate(zip(tpr_ch[:], fpr_ch[:], auc_ch[:], labels[6:8])):\n",
    "    if i==1: plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L,auc*100.), linewidth=1.5, color=colors[2], alpha=0.6)\n",
    "    else: plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L,auc*100.), linewidth=1.5, color=colors[2])\n",
    "\n",
    "for i, (tpr, fpr, auc, L) in enumerate(zip(tpr_to[:], fpr_to[:], auc_to[:], labels[8:])):\n",
    "    if i==1: plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L,auc*100.), linewidth=1.5, color=colors[3], alpha=0.6)\n",
    "    else: plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L,auc*100.), linewidth=1.5, color=colors[3])\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend(bbox_to_anchor=[1.2, 0.5],loc='best',frameon=True)\n",
    "plt.tight_layout()\n",
    "plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
    "plt.axvline(0.00001, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
