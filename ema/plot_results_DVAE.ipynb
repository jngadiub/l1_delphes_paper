{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from losses import kl_loss\n",
    "#import mplhep as hep\n",
    "#plt.style.use(hep.style.CMS)\n",
    "#hep.rcParams[\"yaxis.labellocation\"] = 'center'\n",
    "#hep.rcParams[\"xaxis.labellocation\"] = 'center'\n",
    "#from losses import threeD_loss, split_3D_loss, mse_split_loss, mse_split_particles_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'VAE_result_qkeras16_1610_half.h5'\n",
    "data = h5py.File(input_dir, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm_labels = ['Leptoquark','A to 4 leptons', 'hChToTauNu', 'hToTauTau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QCD\n",
    "# for VAE results - QCD = input, QCD_input = target - not anymore (14/06/2021)\n",
    "X_test_scaled = data['QCD'][:]\n",
    "X_test = data['QCD_input'][:]\n",
    "qcd_prediction = data['predicted_QCD'][:]\n",
    "qcd_mean = data['encoded_mean_QCD'][:]\n",
    "qcd_logvar = data['encoded_logvar_QCD'][:]\n",
    "qcd_z = data['encoded_z_QCD'][:]\n",
    "\n",
    "\n",
    "#BSM\n",
    "bsm_prediction = []; bsm_data = []; bsm_mean = []; bsm_logvar = []; bsm_z = []; bsm_target=[]\n",
    "for bsm in bsm_labels[:]:\n",
    "    bsm_target.append(data[bsm+'_scaled'][:])\n",
    "    bsm_data.append(data[bsm+'_input'][:])\n",
    "    bsm_prediction.append(data['predicted_'+ bsm][:])\n",
    "    bsm_mean.append(data['encoded_mean_'+bsm][:])\n",
    "    bsm_logvar.append(data['encoded_logvar_'+bsm][:])\n",
    "    bsm_z.append(data['encoded_z_'+bsm][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = data['loss'][:]\n",
    "# val_loss = data['val_loss'][:]\n",
    "# kl_loss = data['kl_loss'][:]\n",
    "# val_kl_loss = data['val_kl_loss'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check distributions of mean and logvar from latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(qcd_mean[:,0], bins=200, histtype='step', density=True, range=(-5,5))\n",
    "plt.hist(qcd_mean[:,1], bins=200, histtype='step', density=True, range=(-5,5))\n",
    "plt.hist(qcd_mean[:,2], bins=200, histtype='step', density=True, range=(-5,5))\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.ylabel('Prob. Density(a.u.)')\n",
    "plt.tight_layout()\n",
    "plt.legend(['qcd mean 1', 'qcd mean 2', 'qcd mean 3'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_sigma = np.sqrt(np.exp(qcd_logvar))\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(qcd_logvar[:,0], bins=100, histtype='step', density=True, range=(-20,10))\n",
    "plt.hist(qcd_logvar[:,1], bins=100, histtype='step', density=True, range=(-20,10))\n",
    "plt.hist(qcd_logvar[:,2], bins=100, histtype='step', density=True, range=(-20,10))\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.ylabel('Prob. Density(a.u.)')\n",
    "plt.tight_layout()\n",
    "plt.legend(['qcd logvar 1', 'qcd logvar 2', 'qcd logvar 3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(bsm_mean[0][:,0], bins=200, histtype='step', density=True, range=(-5,5))\n",
    "plt.hist(bsm_mean[0][:,1], bins=200, histtype='step', density=True, range=(-5,5))\n",
    "plt.hist(bsm_mean[0][:,2], bins=200, histtype='step', density=True, range=(-5,5))\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.ylabel('Prob. Density(a.u.)')\n",
    "plt.tight_layout()\n",
    "plt.legend(['LQ mean 1', 'LQ mean 2', 'LQ mean 3'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(bsm_mean[1][:,0], bins=200, histtype='step', density=True, range=(-5,5))\n",
    "plt.hist(bsm_mean[1][:,1], bins=200, histtype='step', density=True, range=(-5,5))\n",
    "plt.hist(bsm_mean[1][:,2], bins=200, histtype='step', density=True, range=(-5,5))\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.ylabel('Prob. Density(a.u.)')\n",
    "plt.tight_layout()\n",
    "plt.legend(['Ato4l mean 1', 'Ato4l mean 2', 'Ato4l mean 3'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b_sigma_1 = np.sqrt(np.exp(bsm_logvar[0]))\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(bsm_logvar[0][:,0], bins=100, histtype='step', density=True, range=(-50, 5))\n",
    "plt.hist(bsm_logvar[0][:,1], bins=100, histtype='step', density=True, range=(-50, 5))\n",
    "plt.hist(bsm_logvar[0][:,2], bins=100, histtype='step', density=True, range=(-50, 5))\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.ylabel('Prob. Density(a.u.)')\n",
    "plt.tight_layout()\n",
    "plt.legend(['LQ sigma 1', 'LQ sigma 2', 'LQ sigma 3'])\n",
    "plt.show()\n",
    "\n",
    "b_sigma_2 = np.sqrt(np.exp(bsm_logvar[1]))\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(bsm_logvar[1][:,0], bins=100, histtype='step', density=True, range=(-100, 5))\n",
    "plt.hist(bsm_logvar[1][:,1], bins=100, histtype='step', density=True, range=(-100, 5))\n",
    "plt.hist(bsm_logvar[1][:,2], bins=100, histtype='step', density=True, range=(-100, 5))\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.ylabel('Prob. Density(a.u.)')\n",
    "plt.tight_layout()\n",
    "plt.legend(['Ato4l sigma 1', 'Ato4l sigma 2', 'Ato4l sigma 3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot features Test vs Prediction - QCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_plots(true, prediction, xlabel, particle, bins, density, ranges=None):\n",
    "    print(find_min_max_range(true, prediction))\n",
    "    plt.figure(figsize=(7,5))\n",
    "    if ranges == None: ranges = find_min_max_range(true, prediction) \n",
    "    plt.hist(prediction, bins=bins, histtype='step', density=density, range = ranges)\n",
    "    plt.hist(true, bins=bins, histtype='step', density=density, range = ranges)\n",
    "    plt.yscale('log', nonpositive='clip')\n",
    "    plt.ylabel('Prob. Density(a.u.)')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.tight_layout()\n",
    "    plt.legend([particle+' Predicted', particle+' True'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_delta_feature_plots(true, prediction, xlabel, particle, bins, density, ranges=None, phi=False):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    if phi:\n",
    "        delta = (true - prediction)/true\n",
    "        xlabel = xlabel+' pull'\n",
    "    else: \n",
    "        delta = (true - prediction)/true\n",
    "        xlabel = xlabel+' pull'\n",
    "    plt.hist(delta, bins=bins, histtype='step', density=density, range=ranges, label=particle)\n",
    "    plt.axvline(delta.mean(), color='k', linestyle='dashed', linewidth=1, label='mean = '+str(round(delta.mean(),2)))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.yscale('log', nonpositive='clip')\n",
    "    plt.ylabel('Prob. Density(a.u.)')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.tight_layout()\n",
    "    plt.annotate('RMS =  %.2f' % np.sqrt(np.mean(delta**2)), xy=(0, 1), xytext=(12, -12), va='top',\\\n",
    "            xycoords='axes fraction', textcoords='offset points')\n",
    "    #plt.show()\n",
    "    \n",
    "    if 'pT' in xlabel: xlabel = 'pT'\n",
    "    elif 'phi' in xlabel: xlabel = 'phi'\n",
    "    elif 'eta' in xlabel: xlabel = 'eta'\n",
    "    \n",
    "    plt.savefig(f'plots/{particle}_{xlabel}_zscore_dnn_vae.pdf', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_max_range(true, pred):\n",
    "    minRange = min(true)\n",
    "    minPred = min(pred)\n",
    "    if minPred < minRange: minRange = minPred\n",
    "        \n",
    "    maxRange = max(true)\n",
    "    maxPred = max(pred)\n",
    "    if maxPred > maxRange: maxRange = maxPred\n",
    "        \n",
    "    return (minRange, maxRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask_met = X_test[:,0:1]!=0\n",
    "mask_met_delete = np.where(X_test[:,0:1].reshape(X_test.shape[0]*1)==0)[0]\n",
    "#mask_eg = X_test[:,1:5]!=0\n",
    "mask_eg_delete = np.where(X_test[:,1:5].reshape(X_test.shape[0]*4)==0)[0]\n",
    "#mask_muon = X_test[:,5:9]!=0\n",
    "mask_muon_delete = np.where(X_test[:,5:9].reshape(X_test.shape[0]*4)==0)[0]\n",
    "#mask_jet = X_test[:,9:19]!=0\n",
    "mask_jet_delete = np.where(X_test[:,9:19].reshape(X_test.shape[0]*10)==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape Test and Prediction datasets\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 19, 3, 1)\n",
    "qcd_pred_reshaped = qcd_prediction.reshape(qcd_prediction.shape[0], 19, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MET\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,0:1,0].reshape(X_test.shape[0]*1),mask_met_delete),\\\n",
    "                   np.delete(qcd_prediction[:,0:1,0].reshape(qcd_prediction.shape[0]*1),mask_met_delete),\\\n",
    "                   'pT', 'MET', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,0:1,2].reshape(X_test_scaled.shape[0]*1),mask_met_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,0:1,2].reshape(qcd_prediction.shape[0]*1)))),mask_met_delete),\\\n",
    "                   '$\\phi$', 'MET', 100, True)\n",
    "# Jets\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,9:19,0].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(qcd_prediction[:, 9:19,0].reshape(qcd_prediction.shape[0]*10),mask_jet_delete),\\\n",
    "                   'pT', 'Jets', 100, True, ranges=(0,1000))\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,9:19,1].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                np.delete(tf.make_ndarray(tf.make_tensor_proto(4.0*tf.math.tanh(qcd_prediction[:,9:19,1].reshape(qcd_prediction.shape[0]*10)))),mask_jet_delete),\\\n",
    "                   '$\\eta$', 'Jets', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,9:19,2].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,9:19,2].reshape(qcd_prediction.shape[0]*10)))),mask_jet_delete),\\\n",
    "                   '$\\phi$', 'Jets', 100, True) # wrap phi\n",
    "# Muons\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,5:9,0].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(qcd_prediction[:,5:9,0].reshape(qcd_prediction.shape[0]*4),mask_muon_delete),\\\n",
    "                    'pT', 'Muons', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,5:9,1].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(2.1*tf.math.tanh(qcd_prediction[:,5:9,1].reshape(qcd_prediction.shape[0]*4)))),mask_muon_delete),\\\n",
    "                   '$\\eta$', 'Muons', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,5:9,2].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,5:9,2].reshape(qcd_prediction.shape[0]*4)))),mask_muon_delete),\\\n",
    "                   '$\\phi$', 'Muons', 100, True)\n",
    "#EGammas\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,1:5,0].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(qcd_prediction[:,1:5,0].reshape(qcd_prediction.shape[0]*4),mask_eg_delete),\\\n",
    "                   'pT', 'EGammas', 100, True, ranges = (0.75937235, 500))\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,1:5,1].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(3.0*tf.math.tanh(qcd_prediction[:,1:5,1].reshape(qcd_prediction.shape[0]*4)))),mask_eg_delete),\\\n",
    "                   '$\\eta$', 'EGammas', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,1:5,2].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,1:5,2].reshape(qcd_prediction.shape[0]*4)))),mask_eg_delete),\\\n",
    "                   '$\\phi$', 'EGammas', 100, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot features (Test - Prediction) - QCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MET\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,0:1,0].reshape(X_test.shape[0]*1),mask_met_delete),\\\n",
    "                   np.delete(qcd_prediction[:,0:1,0].reshape(qcd_prediction.shape[0]*1),mask_met_delete),\\\n",
    "                   'pT', 'MET', 200, True, ranges=(-1000, 1000))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,0:1,2].reshape(X_test.shape[0]*1),mask_met_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,0:1,2].reshape(qcd_prediction.shape[0]*1)))),mask_met_delete),\\\n",
    "                   '$\\phi$', 'MET', 200, True, phi=True, ranges=(-200, 200)) # wrap phi\n",
    "# Jets\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,9:19,0].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(qcd_prediction[:, 9:19,0].reshape(qcd_prediction.shape[0]*10),mask_jet_delete),\\\n",
    "                   'pT', 'Jets', 200, True, ranges=(-10000, 10000))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,9:19,1].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(4.0*tf.math.tanh(qcd_prediction[:,9:19,1].reshape(qcd_prediction.shape[0]*10)))),mask_jet_delete),\\\n",
    "                   '$\\eta$', 'Jets', 200, True,phi=True, ranges=(-250,250))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,9:19,2].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,9:19,2].reshape(qcd_prediction.shape[0]*10)))),mask_jet_delete),\\\n",
    "                   '$\\phi$', 'Jets', 200, True, phi=True, ranges=(-250, 250)) # wrap phi\n",
    "# Muons\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,5:9,0].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(qcd_prediction[:,5:9,0].reshape(qcd_prediction.shape[0]*4),mask_muon_delete),\\\n",
    "                    'pT', 'Muons', 200, True, ranges=(-1000,1000))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,5:9,1].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                 np.delete(tf.make_ndarray(tf.make_tensor_proto(2.1*tf.math.tanh(qcd_prediction[:,5:9,1].reshape(qcd_prediction.shape[0]*4)))),mask_muon_delete),\\\n",
    "                   '$\\eta$', 'Muons', 200, True, phi=True, ranges=(-100, 100))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,5:9,2].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,5:9,2].reshape(qcd_prediction.shape[0]*4)))),mask_muon_delete),\\\n",
    "                  '$\\phi$', 'Muons', 200, True, phi=True, ranges=(-100, 100))\n",
    "#EGammas\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,1:5,0].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(qcd_prediction[:,1:5,0].reshape(qcd_prediction.shape[0]*4),mask_eg_delete),\\\n",
    "                   'pT', 'EGammas', 200, True, ranges=(-1000, 1000))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,1:5,1].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(3.0*tf.math.tanh(qcd_prediction[:,1:5,1].reshape(qcd_prediction.shape[0]*4)))),mask_eg_delete),\\\n",
    "                   '$\\eta$', 'EGammas', 200, True, phi=True, ranges=(-100, 100))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,1:5,2].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,1:5,2].reshape(qcd_prediction.shape[0]*4)))),mask_eg_delete),\\\n",
    "                   '$\\phi$', 'EGammas', 200, True, phi=True, ranges=(-100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss for QCD and BSM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import make_mse_loss_numpy, radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_total_mse_loss(loss, X_test, qcd_prediction, bsm_t, bsm_prediction):\n",
    "    total_loss = []\n",
    "    total_loss.append(loss(X_test, qcd_prediction.astype(np.float32)))\n",
    "    for b, bsm_pred in zip(bsm_t, bsm_prediction):\n",
    "        total_loss.append(loss(b, bsm_pred.astype(np.float32)))\n",
    "    return total_loss\n",
    "\n",
    "def return_total_kl_loss(loss, qcd_mean, qcd_logvar, bsm_mean, bsm_logvar):\n",
    "    total_loss = []\n",
    "    total_loss.append(loss(qcd_mean.astype(np.float32), qcd_logvar.astype(np.float32)))\n",
    "    for mean, logvar in zip(bsm_mean, bsm_logvar):\n",
    "        total_loss.append(loss(mean.astype(np.float32), logvar.astype(np.float32)))\n",
    "\n",
    "def return_total_radius(qcd_mean, qcd_logvar, bsm_mean, bsm_logvar):\n",
    "    total_radius=[]\n",
    "    total_radius.append(radius(qcd_mean.astype(np.float32), qcd_logvar.astype(np.float32)))\n",
    "    for mean, logvar in zip(bsm_mean, bsm_logvar):\n",
    "        total_radius.append(radius(mean.astype(np.float32), logvar.astype(np.float32)))\n",
    "    return total_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_total_loss = return_total_mse_loss(make_mse_loss_numpy, X_test_scaled, qcd_prediction, bsm_target, bsm_prediction)\n",
    "\n",
    "kl_total_loss = return_total_kl_loss(kl_loss_calc, qcd_mean, qcd_logvar, bsm_mean, bsm_logvar)\n",
    "\n",
    "total_loss=[]\n",
    "for mse_loss, kl_loss in zip(mse_total_loss, kl_total_loss):\n",
    "    print(mse_loss.shape)\n",
    "    print(kl_loss.shape)\n",
    "    total_loss.append(np.add(mse_loss, kl_loss))\n",
    "\n",
    "total_radius = return_total_radius(qcd_mean, qcd_logvar, bsm_mean, bsm_logvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['QCD multijet', 'Leptoquark','A to 4 leptons', 'hChToTauNu', 'hToTauTau']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_loss = tot_loss\n",
    "minScore = 999999.\n",
    "maxScore = 0\n",
    "for i in range(len(labels[:])):\n",
    "    thisMin = np.min(total_loss[i])\n",
    "    thisMax = np.max(total_loss[i])\n",
    "    minScore = min(thisMin, minScore)\n",
    "    maxScore = max(maxScore, thisMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size=200\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, label in enumerate(labels[:]):\n",
    "    plt.hist(total_loss[i], bins=bin_size, density=True, log=True, label=label, range=(minScore, 1000),\n",
    "         histtype='step', fill=False, linewidth=1.5)\n",
    "#plt.semilogx()\n",
    "plt.semilogy()\n",
    "#plt.title('MSE')\n",
    "plt.xlabel(\"VAE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.title('(MSE split + KL) loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE (Reconstruction) loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minScore = 999999.\n",
    "maxScore = 0\n",
    "for i in range(len(labels)):\n",
    "    thisMin = np.min(mse_total_loss[i])\n",
    "    thisMax = np.max(mse_total_loss[i])\n",
    "    minScore = min(thisMin, minScore)\n",
    "    maxScore = max(maxScore, thisMax)\n",
    "for i in range(len(labels)):\n",
    "    thisMin = np.min(kl_total_loss[i])\n",
    "    thisMax = np.max(kl_total_loss[i])\n",
    "    minScore = min(thisMin, minScore)\n",
    "    maxScore = max(maxScore, thisMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size=200;colors=['C1', 'C2', 'C3', 'C4', 'C5']\n",
    "plt.figure(figsize=(15,13))\n",
    "for i, label in enumerate(labels):\n",
    "    plt.hist(mse_total_loss[i], bins=bin_size, density=True, log=True, label=label+' MSE', range=(minScore, 50),\n",
    "         histtype='step', fill=False, linewidth=1.5, color=colors[i])\n",
    "    plt.hist(kl_total_loss[i], bins=bin_size, label=label+' KL', density = True, log=True, range=(minScore, 50),\n",
    "         histtype='step', fill=False, linewidth=1.5, color=colors[i], alpha=0.5)\n",
    "#plt.semilogx()\n",
    "plt.semilogy()\n",
    "#plt.title('MSE')\n",
    "plt.xlabel(\"VAE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "#plt.title('Not quantized model')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KL divergence loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minScore = 999999.\n",
    "maxScore = 0\n",
    "for i in range(len(labels)):\n",
    "    thisMin = np.min(kl_total_loss[i])\n",
    "    thisMax = np.max(kl_total_loss[i])\n",
    "    minScore = min(thisMin, minScore)\n",
    "    maxScore = max(maxScore, thisMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size=200\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, label in enumerate(labels):\n",
    "    plt.hist(kl_total_loss[i].reshape(kl_total_loss[i].shape[0]*1), bins=bin_size, label=label, density = True, range=(minScore, 1),\n",
    "         histtype='step', fill=False, linewidth=1.5)\n",
    "#plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.title('KL loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Radius loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_radius = []\n",
    "for radius in total_radius:\n",
    "    r = np.nan_to_num(radius)\n",
    "    r[r==-np.inf] = 0\n",
    "    r[r==np.inf] = 0\n",
    "    r[r>=1E308] = 0\n",
    "    tot_radius.append(r)\n",
    "del total_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minS = 999999.\n",
    "maxS = 0.\n",
    "for i in range(len(tot_radius)):\n",
    "    thisMin = np.min(tot_radius[i])\n",
    "    thisMax = np.max(tot_radius[i])\n",
    "    minS = min(thisMin, minS)\n",
    "    maxS = max(maxS, thisMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, label in enumerate(labels):\n",
    "    plt.hist(tot_radius[i], bins=200, label=label, density=True, range=(minS, 1000),\n",
    "             histtype='step', fill=False, linewidth=1.5)\n",
    "plt.semilogy()\n",
    "plt.title(' ')\n",
    "plt.xlabel(\"$\\mu^2 / \\sigma^2$\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['C1','C2', 'C3', 'C4']\n",
    "#colors   = ['#a6bddb','#67a9cf','#3690c0','#02818a','#016c59','#014636']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_lq=[];fpr_lq=[];auc_lq=[]\n",
    "tpr_ato4l=[];fpr_ato4l=[];auc_ato4l=[]\n",
    "tpr_ch=[];fpr_ch=[];auc_ch=[]\n",
    "tpr_to=[];fpr_to=[];auc_to=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tpr, fpr, auc for total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_qcd = np.zeros(total_loss[0].shape[0])\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    if i == 0: continue\n",
    "    trueVal = np.concatenate((np.ones(total_loss[i].shape[0]), target_qcd))\n",
    "    predVal_loss = np.concatenate((total_loss[i], total_loss[0]))\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "    if i==1:\n",
    "        tpr_lq.append(tpr_loss)\n",
    "        fpr_lq.append(fpr_loss)\n",
    "        auc_lq.append(auc_loss)\n",
    "    elif i == 2:\n",
    "        tpr_ato4l.append(tpr_loss)\n",
    "        fpr_ato4l.append(fpr_loss)\n",
    "        auc_ato4l.append(auc_loss)\n",
    "    elif i==3:\n",
    "        tpr_ch.append(tpr_loss)\n",
    "        fpr_ch.append(fpr_loss)\n",
    "        auc_ch.append(auc_loss)\n",
    "    elif i == 4:\n",
    "        tpr_to.append(tpr_loss)\n",
    "        fpr_to.append(fpr_loss)\n",
    "        auc_to.append(auc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tpr, fpr, auc for MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_qcd = np.zeros(mse_total_loss[0].shape[0])\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    if i == 0: continue\n",
    "    trueVal = np.concatenate((np.ones(mse_total_loss[i].shape[0]), target_qcd))\n",
    "    predVal_loss = np.concatenate((mse_total_loss[i], mse_total_loss[0]))\n",
    "\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "    if i==1:\n",
    "        tpr_lq.append(tpr_loss)\n",
    "        fpr_lq.append(fpr_loss)\n",
    "        auc_lq.append(auc_loss)\n",
    "    elif i == 2:\n",
    "        tpr_ato4l.append(tpr_loss)\n",
    "        fpr_ato4l.append(fpr_loss)\n",
    "        auc_ato4l.append(auc_loss)\n",
    "    elif i==3:\n",
    "        tpr_ch.append(tpr_loss)\n",
    "        fpr_ch.append(fpr_loss)\n",
    "        auc_ch.append(auc_loss)\n",
    "    elif i == 4:\n",
    "        tpr_to.append(tpr_loss)\n",
    "        fpr_to.append(fpr_loss)\n",
    "        auc_to.append(auc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tpr, fpr, auc for KL divergence loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_qcd = np.zeros(kl_total_loss[0].shape[0])\n",
    "#target_qcd_rand = np.zeros(kl_total_loss[3].shape[0])\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    if i == 0: continue\n",
    "    trueVal = np.concatenate((np.ones(kl_total_loss[i].shape[0]), target_qcd))\n",
    "    predVal_loss = np.concatenate((kl_total_loss[i], kl_total_loss[0]))\n",
    "\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "    if i==1:\n",
    "        tpr_lq.append(tpr_loss)\n",
    "        fpr_lq.append(fpr_loss)\n",
    "        auc_lq.append(auc_loss)\n",
    "    elif i == 2:\n",
    "        tpr_ato4l.append(tpr_loss)\n",
    "        fpr_ato4l.append(fpr_loss)\n",
    "        auc_ato4l.append(auc_loss)\n",
    "    elif i==3:\n",
    "        tpr_ch.append(tpr_loss)\n",
    "        fpr_ch.append(fpr_loss)\n",
    "        auc_ch.append(auc_loss)\n",
    "    elif i == 4:\n",
    "        tpr_to.append(tpr_loss)\n",
    "        fpr_to.append(fpr_loss)\n",
    "        auc_to.append(auc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tpr, fpr, auc for Radius loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_qcd = np.zeros(tot_radius[0].shape[0])\n",
    "#target_qcd_rand = np.zeros(tot_radius[3].shape[0])\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    if i == 0: continue\n",
    "    trueVal = np.concatenate((np.ones(tot_radius[i].shape[0]), target_qcd))\n",
    "    predVal_loss = np.concatenate((tot_radius[i], tot_radius[0]))\n",
    "\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "    if i==1:\n",
    "        tpr_lq.append(tpr_loss)\n",
    "        fpr_lq.append(fpr_loss)\n",
    "        auc_lq.append(auc_loss)\n",
    "    elif i == 2:\n",
    "        tpr_ato4l.append(tpr_loss)\n",
    "        fpr_ato4l.append(fpr_loss)\n",
    "        auc_ato4l.append(auc_loss)\n",
    "    elif i==3:\n",
    "        tpr_ch.append(tpr_loss)\n",
    "        fpr_ch.append(fpr_loss)\n",
    "        auc_ch.append(auc_loss)\n",
    "    elif i == 4:\n",
    "        tpr_to.append(tpr_loss)\n",
    "        fpr_to.append(fpr_loss)\n",
    "        auc_to.append(auc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = ['Total loss', 'MSE VAE ', '$D_{KL}$', '$R_{z}$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r'LQ $\\rightarrow$ b$\\tau$', r'A $\\rightarrow$ 4L', r'$h_{\\pm} \\rightarrow \\tau\\nu$', r'$h_{0} \\rightarrow \\tau\\tau$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROCs for LQ signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, (tpr, fpr, auc, L) in enumerate(zip(tpr_lq[1:], fpr_lq[1:], auc_lq[1:], losses[1:])):\n",
    "    if i >= 4:\n",
    "        plt.plot(fpr, tpr, \"-\", linewidth=1.5, color=colors[i-4], alpha=0.4)\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L ,auc*100.), linewidth=1.5, color=colors[i])\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower right',frameon=True, fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
    "plt.axvline(0.00001, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"ROC \"+labels[0]+\" Baseline Pruned\")\n",
    "#plt.savefig('ROC_LQ.pdf', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROCs for A to 4 leptons signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, (tpr, fpr, auc, L) in enumerate(zip(tpr_ato4l[1:], fpr_ato4l[1:], auc_ato4l[1:], losses[1:])):\n",
    "    if i >= 4:\n",
    "        plt.plot(fpr, tpr, \"-\",linewidth=1.5, color=colors[i-4],alpha=0.4)\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L ,auc*100.), linewidth=1.5, color=colors[i])\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower right',frameon=True, fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
    "plt.axvline(0.00001, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"ROC \"+labels[1]+\" Baseline Pruned\")\n",
    "#plt.savefig('ROC_ato4l.pdf', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROCs for higgs charged signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, (tpr, fpr, auc, L) in enumerate(zip(tpr_ch[1:], fpr_ch[1:], auc_ch[1:], losses[1:])):\n",
    "    if i >= 4:\n",
    "        plt.plot(fpr, tpr, \"-\", linewidth=1.5, color=colors[i-4],alpha=0.5)\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, \"-\", label='%s (auc = %.1f%%)'%(L ,auc*100.), linewidth=1.5, color=colors[i])\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower right',frameon=True, fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
    "plt.axvline(0.00001, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"ROC \"+labels[2]+\" Baseline Pruned\")\n",
    "#plt.savefig('ROC_CH.pdf', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROCs for higgs signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, (tpr, fpr, auc, L) in enumerate(zip(tpr_to[1:], fpr_to[1:], auc_to[1:], losses[1:])):\n",
    "    if i >= 4:\n",
    "        plt.plot(fpr, tpr, \"-\", linewidth=1.5, color=colors[i-4],alpha=0.5)\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, \"-\", label='%s ROC (auc = %.1f%%)'%(L ,auc*100.), linewidth=1.5, color=colors[i])\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower right',frameon=True, fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
    "plt.axvline(0.00001, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"ROC \"+labels[3]+\" Baseline Pruned\")\n",
    "plt.savefig('ROC_TO.pdf', facecolor='white')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
