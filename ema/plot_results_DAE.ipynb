{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "#from losses import threeD_loss, split_3D_loss, mse_split, mse_split_particles_loss, kl_loss\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "#import mplhep as hep\n",
    "#plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'AE_result_pruned.h5'\n",
    "data = h5py.File(input_dir, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm_labels = ['Leptoquark','A to 4 leptons', 'hChToTauNu', 'hToTauTau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QCD\n",
    "X_test_scaled = data['QCD'][:]\n",
    "X_test = data['QCD_input'][:]\n",
    "qcd_prediction = data['predicted_QCD'][:]\n",
    "\n",
    "\n",
    "#BSM\n",
    "bsm_prediction=[]; bsm_target = []; bsm_prediction_board=[]; bsm_data=[];bsm_prediction_onnx=[]\n",
    "for bsm in bsm_labels:\n",
    "    bsm_data.append(data[bsm+'_input'][:])\n",
    "    #print(data[bsm+'_input'][:].shape)\n",
    "    bsm_target.append(data[bsm+'_scaled'][:])\n",
    "    bsm_prediction.append(data['predicted_'+bsm][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = data['loss'][:]\n",
    "# val_loss = data['val_loss'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training/validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(loss[:], label='Training loss')\n",
    "plt.plot(val_loss[:], label='Validation loss')\n",
    "plt.title('AE - Training and validation loss')\n",
    "#plt.yscale('log', nonposy='clip')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot features Test vs Prediction - QCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_plots(true, prediction, xlabel, particle, bins, density, ranges=None):\n",
    "    print(find_min_max_range(true, prediction))\n",
    "    plt.figure(figsize=(7,5))\n",
    "    if ranges == None: ranges = find_min_max_range(true, prediction) \n",
    "    plt.hist(prediction, bins=bins, histtype='step', density=density, range = ranges)\n",
    "    plt.hist(true, bins=bins, histtype='step', density=density, range = ranges)\n",
    "    plt.yscale('log', nonpositive='clip')\n",
    "    plt.ylabel('Prob. Density(a.u.)')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.tight_layout()\n",
    "    plt.legend([particle+' Predicted', particle+' True'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_delta_feature_plots(true, prediction, xlabel, particle, bins, density, ranges=None, phi=False):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    if phi:\n",
    "        delta = (true - prediction)/true\n",
    "        xlabel = xlabel+' pull'\n",
    "    else: \n",
    "        delta = (true - prediction)/true\n",
    "        xlabel = xlabel+' pull'\n",
    "    plt.hist(delta, bins=bins, histtype='step', density=density, range=ranges, label=particle)\n",
    "    plt.axvline(delta.mean(), color='k', linestyle='dashed', linewidth=1, label='mean = '+str(round(delta.mean(),2)))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.yscale('log', nonpositive='clip')\n",
    "    plt.ylabel('Prob. Density(a.u.)')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.tight_layout()\n",
    "    plt.annotate('RMS =  %.2f' % np.sqrt(np.mean(delta**2)), xy=(0, 1), xytext=(12, -12), va='top',\\\n",
    "            xycoords='axes fraction', textcoords='offset points')\n",
    "    #plt.show()\n",
    "    \n",
    "    if 'pT' in xlabel: xlabel = 'pT'\n",
    "    elif 'phi' in xlabel: xlabel = 'phi'\n",
    "    elif 'eta' in xlabel: xlabel = 'eta'\n",
    "    \n",
    "    plt.savefig(f'plots/{particle}_{xlabel}_zscore.pdf', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_max_range(true, pred):\n",
    "    minRange = min(true)\n",
    "    minPred = min(pred)\n",
    "    if minPred < minRange: minRange = minPred\n",
    "        \n",
    "    maxRange = max(true)\n",
    "    maxPred = max(pred)\n",
    "    if maxPred > maxRange: maxRange = maxPred\n",
    "        \n",
    "    return (minRange, maxRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask_met = X_test[:,0:1]!=0\n",
    "mask_met_delete = np.where(X_test[:,0:1].reshape(X_test.shape[0]*1)==0)[0]\n",
    "#mask_eg = X_test[:,1:5]!=0\n",
    "mask_eg_delete = np.where(X_test[:,1:5].reshape(X_test.shape[0]*4)==0)[0]\n",
    "#mask_muon = X_test[:,5:9]!=0\n",
    "mask_muon_delete = np.where(X_test[:,5:9].reshape(X_test.shape[0]*4)==0)[0]\n",
    "#mask_jet = X_test[:,9:19]!=0\n",
    "mask_jet_delete = np.where(X_test[:,9:19].reshape(X_test.shape[0]*10)==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape Test and Prediction datasets\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 19, 3, 1)\n",
    "qcd_pred_reshaped = qcd_prediction.reshape(qcd_prediction.shape[0], 19, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MET\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,0:1,0].reshape(X_test.shape[0]*1),mask_met_delete),\\\n",
    "                   np.delete(qcd_prediction[:,0:1,0].reshape(qcd_prediction.shape[0]*1),mask_met_delete),\\\n",
    "                   'pT', 'MET', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,0:1,2].reshape(X_test_scaled.shape[0]*1),mask_met_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,0:1,2].reshape(qcd_prediction.shape[0]*1)))),mask_met_delete),\\\n",
    "                   '$\\phi$', 'MET', 100, True)\n",
    "# Jets\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,9:19,0].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(qcd_prediction[:, 9:19,0].reshape(qcd_prediction.shape[0]*10),mask_jet_delete),\\\n",
    "                   'pT', 'Jets', 100, True, ranges=(0,1000))\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,9:19,1].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                np.delete(tf.make_ndarray(tf.make_tensor_proto(4.0*tf.math.tanh(qcd_prediction[:,9:19,1].reshape(qcd_prediction.shape[0]*10)))),mask_jet_delete),\\\n",
    "                   '$\\eta$', 'Jets', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,9:19,2].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,9:19,2].reshape(qcd_prediction.shape[0]*10)))),mask_jet_delete),\\\n",
    "                   '$\\phi$', 'Jets', 100, True) # wrap phi\n",
    "# Muons\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,5:9,0].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(qcd_prediction[:,5:9,0].reshape(qcd_prediction.shape[0]*4),mask_muon_delete),\\\n",
    "                    'pT', 'Muons', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,5:9,1].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(2.1*tf.math.tanh(qcd_prediction[:,5:9,1].reshape(qcd_prediction.shape[0]*4)))),mask_muon_delete),\\\n",
    "                   '$\\eta$', 'Muons', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,5:9,2].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,5:9,2].reshape(qcd_prediction.shape[0]*4)))),mask_muon_delete),\\\n",
    "                   '$\\phi$', 'Muons', 100, True)\n",
    "#EGammas\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,1:5,0].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(qcd_prediction[:,1:5,0].reshape(qcd_prediction.shape[0]*4),mask_eg_delete),\\\n",
    "                   'pT', 'EGammas', 100, True, ranges = (0.75937235, 500))\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,1:5,1].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(3.0*tf.math.tanh(qcd_prediction[:,1:5,1].reshape(qcd_prediction.shape[0]*4)))),mask_eg_delete),\\\n",
    "                   '$\\eta$', 'EGammas', 100, True)\n",
    "make_feature_plots(np.delete(X_test_reshaped[:,1:5,2].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,1:5,2].reshape(qcd_prediction.shape[0]*4)))),mask_eg_delete),\\\n",
    "                   '$\\phi$', 'EGammas', 100, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot features (Test - Prediction) - QCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_delta_feature_plots' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d8d0e84a17b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# MET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m make_delta_feature_plots(np.delete(X_test_scaled[:,0:1].reshape(X_test.shape[0]*1),mask_met_delete),\\\n\u001b[0m\u001b[1;32m      3\u001b[0m                    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqcd_prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqcd_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_met_delete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    'pT', 'MET', 200, True, ranges=(-10000, 10000))\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#make_delta_feature_plots(np.delete(X_test_reshaped[:,0, 1, :].reshape(X_test.shape[0]*1),indexes_met),\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_delta_feature_plots' is not defined"
     ]
    }
   ],
   "source": [
    "# MET\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,0:1,0].reshape(X_test.shape[0]*1),mask_met_delete),\\\n",
    "                   np.delete(qcd_prediction[:,0:1,0].reshape(qcd_prediction.shape[0]*1),mask_met_delete),\\\n",
    "                   'pT', 'MET', 200, True, ranges=(-1000, 1000))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,0:1,2].reshape(X_test.shape[0]*1),mask_met_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,0:1,2].reshape(qcd_prediction.shape[0]*1)))),mask_met_delete),\\\n",
    "                   '$\\phi$', 'MET', 200, True, phi=True, ranges=(-200, 200)) # wrap phi\n",
    "# Jets\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,9:19,0].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(qcd_prediction[:, 9:19,0].reshape(qcd_prediction.shape[0]*10),mask_jet_delete),\\\n",
    "                   'pT', 'Jets', 200, True, ranges=(-10000, 10000))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,9:19,1].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(4.0*tf.math.tanh(qcd_prediction[:,9:19,1].reshape(qcd_prediction.shape[0]*10)))),mask_jet_delete),\\\n",
    "                   '$\\eta$', 'Jets', 200, True,phi=True, ranges=(-250,250))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,9:19,2].reshape(X_test.shape[0]*10),mask_jet_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,9:19,2].reshape(qcd_prediction.shape[0]*10)))),mask_jet_delete),\\\n",
    "                   '$\\phi$', 'Jets', 200, True, phi=True, ranges=(-250, 250)) # wrap phi\n",
    "# Muons\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,5:9,0].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(qcd_prediction[:,5:9,0].reshape(qcd_prediction.shape[0]*4),mask_muon_delete),\\\n",
    "                    'pT', 'Muons', 200, True, ranges=(-1000,1000))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,5:9,1].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                 np.delete(tf.make_ndarray(tf.make_tensor_proto(2.1*tf.math.tanh(qcd_prediction[:,5:9,1].reshape(qcd_prediction.shape[0]*4)))),mask_muon_delete),\\\n",
    "                   '$\\eta$', 'Muons', 200, True, phi=True, ranges=(-100, 100))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,5:9,2].reshape(X_test.shape[0]*4),mask_muon_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,5:9,2].reshape(qcd_prediction.shape[0]*4)))),mask_muon_delete),\\\n",
    "                  '$\\phi$', 'Muons', 200, True, phi=True, ranges=(-100, 100))\n",
    "#EGammas\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,1:5,0].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(qcd_prediction[:,1:5,0].reshape(qcd_prediction.shape[0]*4),mask_eg_delete),\\\n",
    "                   'pT', 'EGammas', 200, True, ranges=(-1000, 1000))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,1:5,1].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(3.0*tf.math.tanh(qcd_prediction[:,1:5,1].reshape(qcd_prediction.shape[0]*4)))),mask_eg_delete),\\\n",
    "                   '$\\eta$', 'EGammas', 200, True, phi=True, ranges=(-100, 100))\n",
    "make_delta_feature_plots(np.delete(X_test_reshaped[:,1:5,2].reshape(X_test.shape[0]*4),mask_eg_delete),\\\n",
    "                   np.delete(tf.make_ndarray(tf.make_tensor_proto(math.pi*tf.math.tanh(qcd_prediction[:,1:5,2].reshape(qcd_prediction.shape[0]*4)))),mask_eg_delete),\\\n",
    "                   '$\\phi$', 'EGammas', 200, True, phi=True, ranges=(-100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss for QCD and BSM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import make_mse_loss_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_total_loss(loss, X, qcd_pred, bsm_t, bsm_pred):\n",
    "    \n",
    "    total_loss = []\n",
    "    total_loss.append(loss(X, qcd_pred.astype(np.float32)))\n",
    "    for i, bsm_i in enumerate(bsm_t):\n",
    "        total_loss.append(loss(bsm_i, bsm_pred[i].astype(np.float32)))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss used\n",
    "loss = make_mse_loss_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = return_total_loss(loss, X_test_scaled, qcd_prediction, bsm_target, bsm_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['QCD multijet', 'Leptoquark', 'A to 4 leptons', 'hChToTauNu', 'hToTauTau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minScore = 999999.\n",
    "maxScore = 0\n",
    "for i in range(len(labels)):\n",
    "    thisMin = np.min(total_loss[i])\n",
    "    thisMax = np.max(total_loss[i])\n",
    "    minScore = min(thisMin, minScore)\n",
    "    maxScore = max(maxScore, thisMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size=100\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, label in enumerate(labels):\n",
    "    print(len(total_loss[i]))\n",
    "    plt.hist(total_loss[i], bins=bin_size, label=label, density = True,\n",
    "         histtype='step', fill=False, linewidth=1.5, range=(minScore, 10000))\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.title('MSE')\n",
    "plt.xlabel(\"Autoencoder Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.title('MSE split loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['C0','C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leptoquark_results=[]; ato4l_results=[]; ch_results=[]; to_results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_legend = [r'LQ $\\rightarrow$ b$\\tau$', r'A $\\rightarrow$ 4L', r'$h_{\\pm} \\rightarrow \\tau\\nu$', r'$h_{0} \\rightarrow \\tau\\tau$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "target_qcd = np.zeros(total_loss[0].shape[0])\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, label in enumerate(labels):\n",
    "    if i == 0: continue\n",
    "    \n",
    "    trueVal = np.concatenate((np.ones(total_loss[i].shape[0]), target_qcd))\n",
    "    predVal_loss = np.concatenate((total_loss[i], total_loss[0]))\n",
    "\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "    plt.plot(fpr_loss, tpr_loss, \"-\", label='%s (auc = %.1f%%)'%('keras '+ labels_legend[i-1],auc_loss*100.), linewidth=1.5, color=colors[i])\n",
    "    if i == 1: \n",
    "        leptoquark_results = [fpr_loss, tpr_loss, auc_loss]\n",
    "        #plt.plot(lepto_results[0][0], lepto_results[0][1], \"-\", label='%s (auc = %.1f%%)'%('hls '+labels_legend[i-1],0.891*100.), linewidth=1.5, color=colors[i], alpha=0.6)\n",
    "    elif i == 2: \n",
    "        ato4l_results = [fpr_loss, tpr_loss, auc_loss]\n",
    "        #plt.plot(ato4l_results[0][0], ato4l_results[0][1], \"-\",label='%s (auc = %.1f%%)'%('hls '+labels_legend[i-1],0.885*100.),  linewidth=1.5, color=colors[i], alpha=0.6)\n",
    "    elif i == 3: \n",
    "        ch_results = [fpr_loss, tpr_loss, auc_loss]\n",
    "        #plt.plot(ch_results[0][0], ch_results[0][1], \"-\", label='%s (auc = %.1f%%)'%('hls '+labels_legend[i-1],0.714*100.), linewidth=1.5, color=colors[i], alpha=0.6)\n",
    "    else: \n",
    "        to_results = [fpr_loss, tpr_loss, auc_loss]\n",
    "        #plt.plot(to_results[0][0], to_results[0][1], \"-\", label='%s (auc = %.1f%%)'%('hls '+labels_legend[i-1],0.585*100.), linewidth=1.5, color=colors[i], alpha=0.6)\n",
    "    plt.semilogx()\n",
    "    plt.semilogy()\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='center right')\n",
    "    plt.tight_layout()\n",
    "plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
    "plt.axvline(0.00001, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"ROC AE\")\n",
    "#plt.savefig('AE_binary_ROCs.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('AE_leptoquark_Results_HLS', leptoquark_results[:-1], delimiter=',')\n",
    "# np.savetxt('AE_ato4l_Results_HLS', ato4l_results[:-1], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('AE_CH_Results_HLS', ch_results[:-1], delimiter=',')\n",
    "# np.savetxt('AE_TO_Results_HLS', to_results[:-1], delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
